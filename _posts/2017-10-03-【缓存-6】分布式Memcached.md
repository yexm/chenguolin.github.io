---
layout:  post  # 使用的布局（不需要改）
catalog: true  # 是否归档
author: 陈国林 # 作者
tags:          #标签
    - 缓存
---

# 一. 经典问题
随着互联网的快速发展和普及，人类进入了大数据时代。大数据时代系统存储的数据量巨大、用户多访问量巨大，由于互联网系统会大量使用 Memcached 作为缓存，而在使用 Memcached 的过程中，产生了特有的经典问题。

## ① 容量问题
Memcached 在使用中，除了存储数据占用内存外，连接的读写缓冲、哈希表分配、辅助线程处理、进程运行等都会占用内存空间，而且操作系统本身也会占用不少内存，为了确保 Mc 的稳定运行，`Mc 的内存设置，一般设为物理内存的 80%`。另外，设置的内存，也不完全是存储有效数据，我上一节课讲到，每个 Item 数据存储在 chunk 时，会有部分字节浪费，另外 key 在过期、失效后，不是立即删除，而是采用延迟淘汰、异步 LRU 队尾扫描的方式清理，这些暂时没有淘汰的、过期失效的 key ，也会占用不少的存储空间。当前大数据时代，互联网系统中的很多核心业务，需要缓存的热数据在 300~500GB 以上，远远超过单机物理内存的容量。

## ② 性能瓶颈
出于系统稳定性考虑，线上 Mc 的访问，最大 QPS 要在 `10~20w` 以下，超过则可能会出现慢查的问题。而对中大型互联网系统，核心业务的缓存请求高达百万级 QPS，仅仅靠简单部署单个物理机、单个资源池很难达到线上的业务要求。

## ③ 连接瓶颈
出于稳定性考虑，线上 Mc 的连接数要控制在 `10w` 以下。以避免连接数过多，导致连接占用大量内存，从而出现命中率下降、甚至慢查超时的问题。对于大中型系统，线上实例高达万级、甚至十万级，单个实例的最小、最大连接数，一般设置在 5~60 个之间。业务实例的连接数远超过单个机器的稳定支撑范围。

## ④ 硬件资源局部故障
由于任何硬件资源，都有一定故障概率，而且在使用 `4` 年后，故障率陡增。对于数以万计的硬件设备，随时都有可能出现机器故障，从而导致 Mc 节点访问性能下降、宕机，海量访问穿透到 DB，引发 DB 过载，最终导致整个系统无法访问，引发雪崩现象。

## ⑤ 流量洪峰下快速扩展
大数据时代，由于信息扩散的扁平化，突发事件、重大活动发生时，海量用户同时蜂拥而至，短时间引发巨大流量。整个系统的访问量相比日常峰值增大 `70%` 以上，同时出现大量的极热 key 的访问，这些极热 key 所在的 Mc 节点，访问量相比日常高峰，增大 `2~3` 倍以上，很容易出现 CPU 飙升、带宽打满、机器负荷严重过载的现象。

