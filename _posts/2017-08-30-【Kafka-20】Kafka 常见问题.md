---
layout:  post    # 使用的布局（不需要改）
catalog: true   # 是否归档
author: 陈国林 # 作者
tags:         #标签
    - Kafka
---

# 一. Kafka的使用场景
Kafka是消息引擎系统，主要的使用场景如下

1. `异步处理`
2. `应用解耦`
3. `流量削锋`: 秒杀活动，一般会因为流量过大，导致流量暴增，应用挂掉。为解决这个问题，一般需要在应用前端加入消息队列。可以控制活动的人数，可以缓解短时间内高流量压垮应用。用户的请求，服务器接收后，首先写入消息队列。假如消息队列长度超过最大数量，则直接抛弃用户请求或跳转到错误页面。秒杀业务根据消息队列中的请求信息，再做后续处理。
4. `日志处理`: 日志处理是指将消息队列用在日志处理中，比如Kafka的应用，解决大量日志传输的问题。日志采集客户端，负责日志数据采集，定时写受写入Kafka队列；Kafka消息队列，负责日志数据的接收，存储和转发；日志处理应用：订阅并消费kafka队列中的日志数据。

# 二. Kafka如何保证高可用
1. Kafka 是一个分布式的消息队列，它可以由多个 broker 组成，每个 broker 是一个节点。我们创建一个 topic 的时候，这个 topic 可以划分为多个partition，每个 partition 可以存在于不同的 broker 上，每个 partition 存放一部分数据。
2. kafka 0.8 版本之前是没有 HA 机制的，就是任何一个 broker 宕机了，那个 broker 上的 partition 就废了，没法写也没法读，没有什么高可用性可言；kafka 0.8 版本之后，提供了 HA 机制，就是 replica 副本机制。kafka 会均匀的将一个 partition 的所有 replica 分布在不同的机器上，来提高容错性。
3. 每个 partition 的数据都会同步到其他机器上，形成自己的多个 replica 副本。然后所有 replica 会选举一个 leader 出来，那么生产和消费都请求 leader，其他 replica 做为 follower，leader 会同步数据给 follower。当 leader 挂了会自动去找 replica，然后会再选举一个 leader 出来，这样就具有高可用性了。写数据的时候，生产者就写 leader，然后 leader 将数据落地写 `本地磁盘`，其他 follower 自己主动从 leader 来 `pull` 数据，保持数据同步。
4. Kafka 通过 Replica 机制来保证高可用，具体做法就是为每个 Partition 保存若干个副本数，每个副本保存在不同的 Broker 上。其中的一个副本充当 Leader副本，负责处理 Producer 和 Consumer 请求，其他副本充当 Follower 角色，由 Kafka controller 负责保证与 Leader 的同步。如果 Leader 所在的 Broker 挂掉了，`Contorller 会检测到然后在 Zookeeper 的帮助下重选出新的 Leader，这个过程会导致 Partition 不可用`。如果每个 Broker 上有很多Partition，当这个 Broker 挂掉的时候，Zookeeper 和 Controller 需要立即对这个 Broker 上的 Partition 进行 Leader 选举，故障恢复的时间会变长。

# 三. 大量消息在消息队列里积压了几个小时怎么解决
一般这个时候，只能操作临时紧急扩容了，具体操作步骤和思路如下

1. 先修复 consumer 的问题，确保其恢复消费速度，然后将现有cnosumer都停掉
2. 新建一个topic，partition是原来的10倍 （或20倍）
3. 写一个临时的分发数据的 consumer程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的topic
4. 接着临时使用10倍 （20倍）的机器来部署原来 consumer（这种做法相当于是临时将partition 和 consumer 扩大10倍，以正常的10倍速度来消费数据）
5. 等快速消费完积压数据之后，恢复原先部署架构，重新用原先的 consumer 机器来消费消息

# 四. Kafka如何保证消息的有序性
1. Kafka 目前只能保证同个 partition 的数据是严格有序的，没办法保证多个partition之间有序
2. 如果要实现全局有序，可以设置topic partition个数为1，这样每个consumer group只能有一个consumer实例在消费，这个时候就能保证数据严格有序
3. 可以让业务做些改造，同一批消息设置一个相同可以。生产端根据key hash进行分区选择，相同key的消息会写入同一个partition，这一就能保证同一批消息是全局有序

# 五. Kafka如何保证数据不丢失
`数据丢失场景`: 写入数据都是往某个Partition的Leader写入的，然后那个Partition的Follower会从Leader 异步Pull数据。如果有1条数据刚写入Leader Partition，还没来得及同步给Follower，Leader Partiton所在机器突然就宕机了呢？

这个时候这条数据是没同步到Partition0的Follower上去的，此时会选举Partition0的ISR列表的Follower作为新的Leader对外提供服务，但是用户是读不到刚才写入的那条数据的，因为Partition0的Follower没有同步到最新的一条数据的，于是这个时候就会造成数据丢失的问题。

所以我们通过以下几点来保证数据不丢失

1. 给这个 topic 设置 replication.factor 参数，这个值必须大于1，要求每个 partition 必须有至少2个副本
2. 每个Partition都至少得有1个Follower在ISR列表里，及时跟Leader保持数据同步。在 kafka 服务端设置 min.insync.replicas 参数，这个值必须大于1，保证 leader 挂了还有一个 follower可以作为新的 leader 提供服务。
3. 在 producer 端设置 acks=all，这个是要求每条数据，必须是写入所有 replica 之后，才能认为是写成功了。`如果 ack=all，那么一定不会丢数据`。leader 接收到消息，所有的 follower 都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次
4. 如果不满足上述两个条件，那就一直写入失败，让生产系统不停的尝试重试，直到满足上述两个条件，然后才能认为写入成功，在 producer 端设置 retries=MAX（很大很大很大的一个值，无限次重试的意思），这个是要求一旦写入失败，就无限重试

# 六. Kafka吞吐量高的原因
Kafka 是高吞吐低延迟的高并发、高性能的消息中间件，在大数据领域有极为广泛的运用，配置良好的Kafka集群甚至可以做到每秒几十万、上百万的超高并发写入。

1. `Kafka是基于操作系统的page cache来实现文件写入的`: 操作系统本身有一层缓存，叫做page cache，是在内存里的缓存，我们也可以称之为os cache，意思就是操作系统自己管理的缓存。你在写入磁盘文件的时候，可以直接写入这个os cache里，也就是仅仅写入内存中，接下来由操作系统自己决定什么时候把os cache里的数据真的刷入磁盘文件中。
2. `顺序写磁盘的方式来写的`: 也就是说仅仅将数据追加到文件的末尾，不是在文件的随机位置来修改数据。通过追加文件末尾，按照顺序的方式来写数据的话，那么这种磁盘顺序写的性能基本上可以跟写内存的性能本身也是差不多的。

# 七. Kafka主从同步怎么实现
1. 在kafka集群中，每个Partition都有多个副本，其中一个副本叫做leader，其他的副本叫做follower
2. 假设一个Topic拆分为了3个Partition，分别是Partition0，Partiton1，Partition2，此时每个Partition都有2个副本。比如Partition0有一个副本是Leader，另外一个副本是Follower，Leader和Follower两个副本是分布在不同机器上的。这样的多副本冗余机制，可以保证任何一台机器挂掉，都不会导致数据彻底丢失，因为起码还是有副本在别的机器上的。
3. 其实任何一个Partition，只有Leader是对外提供读写服务的。也就是说，如果有一个客户端往一个Partition写入数据，此时一般就是写入这个Partition的Leader副本。然后Leader副本接收到数据之后，Follower副本会不停的给他发送请求尝试去`拉取`最新的数据，拉取到自己本地后，写入磁盘中。
4. Kafka服务端可以配置 ISR，ISR全称是 In-Sync Replicas，也就是保持同步的副本。表示跟 Leader 始终保持同步的 Follower 有哪些。每个Partition都有一个ISR列表，这个ISR里一定会有Leader自己，因为Leader肯定数据是最新的，然后就是那些跟Leader保持同步的Follower，也会在ISR里。

# 八. Kafka ACK参数对消息持久化的影响
acks参数是在Kafka 生产客户端设置的，往kafka写数据的时候可以设置这个acks参数，这个参数实际上有三种值可以设置。

1. `acks参数设置为0`: 意思是生产客户端，只要把消息发送出去就认为成功，不管那条数据有没有在 `（这种情况可能丢数据，可能消息还在flight，但是partition leader broker挂了，就会导致数据丢失）`
2. `acks参数设置为1`: 意思是只要Partition Leader接收到消息而且写入本地磁盘了，就认为成功了，不管他其他的Follower有没有成功拉取到这条消息了，这个是大部分kafka生产客户端默认的配置。`（这种情况可能丢数据，当Partition Leader刚刚接收到消息，Follower还没来得及同步过去，结果Leader所在的broker宕机了，此时也会导致这条消息丢失，因为人家客户端已经认为发送成功了）`
3. `设置acks=all`: 意思是Partition Leader接收到消息之后，还必须要求ISR列表里跟Leader保持同步的那些Follower都要把消息同步过去，才能认为这条消息是写入成功了。`（这种情况不会丢数据，如果说Partition Leader刚接收到了消息，但是结果Follower没有收到消息，此时Leader宕机了，那么客户端会感知到这个消息没发送成功，他会重试再次发送消息过去。）`
   
`注意: ack=all 并不能保证数据不会丢失，如果partition只有一个replica，那相当于只有一个leader没有follower，leader挂掉之后partition就不可用`

# 九. Kafka读写都是在Leader上为什么不提供follower读
1. 保证一致性，如果要让follower提供读能力，需要解决leader和flower数据不同步问题，数据不同步必然会引入一致性问题。
2. Kafka每个topic有多个partition，多个partition正常情况下会均匀分散在多个borker上，天然就支持负载均衡的能力。
3. 主从读写分离主要是为了减轻读的压力，但Kafka和Mysql不同，不属于典型的读多写少场景，读写分离的优势不大。


